# AI Multi-Person Pose Estimation System - Independent Docker Services

This project breaks down the AI multi-person pose estimation system into independent Docker services, communicating through MQTT message queues and managed with YAML configuration files.

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RTSP Input    â”‚    â”‚   MQTT Broker   â”‚    â”‚   RTSP Output   â”‚
â”‚ (Video Stream)  â”‚    â”‚  (Message Hub)  â”‚    â”‚ (Visualization) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â–²
         â–¼                       â”‚                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  YOLOX Service  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚              â”‚ Annotation Svc  â”‚
â”‚   (Detection)   â”‚              â”‚              â”‚ (Visualization) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â–²
         â–¼                       â”‚                       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RTMPose Service â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚              â”‚  ByteTrack Svc  â”‚
â”‚ (Pose Estimate) â”‚              â”‚              â”‚   (Tracking)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â–²
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                         MQTT Topics:
                         - yolox
                         - rtmpose  
                         - bytetrack
```

## ğŸ“¦ Service Components

### 1. Base Services
- **MQTT Broker**: Message queue broker, handles inter-service communication
- **RTSP Server**: Streaming media server, handles video input/output
- **MP4 Source**: Video source service

### 2. AI Processing Services
- **YOLOX Service**: Human object detection service
- **RTMPose Service**: Human pose estimation service  
- **ByteTrack Service**: Object tracking service
- **Annotation Service**: Visualization annotation service

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- NVIDIA GPU (for YOLOX and RTMPose services)
- nvidia-docker runtime

### 1. Configuration File

Ensure `pose_estimation_config.yaml` exists in the project root directory:

```yaml
# Key configuration example
global:
  devices: "cuda"
  log_level: "INFO"
  backend: "onnxruntime"

yolox:
  devices: "cuda"
  input:
    config: "rtsp://rtsp-server:8554,topic=mystream"
  output:
    config: "mqtt://mqtt-broker:1883,topic=yolox,qos=2,queue_max_len=50"

# ... other service configurations
```

### 2. Start Services

```bash
# Enter project directory
cd projects/
docker build -t contanos:base-onnx-gpu ./base-onnx-gpu
# Start all services
./start_pose_estimation_services.sh start

# Or use docker-compose directly
docker-compose up -d
```

### 3. Check Service Status

```bash
# Check service status
./start_pose_estimation_services.sh status

# View service logs
./start_pose_estimation_services.sh logs

# View specific service logs
docker-compose logs -f yolox-service
```

## ğŸ”§ Management Commands

```bash
# Start services
./start_pose_estimation_services.sh start

# Stop services
./start_pose_estimation_services.sh stop

# Restart services
./start_pose_estimation_services.sh restart

# View status
./start_pose_estimation_services.sh status

# View logs
./start_pose_estimation_services.sh logs
```

## ğŸ“º Access URLs

### RTSP Stream URLs
- **Input stream (raw video)**: `rtsp://localhost:8554/rawstream`
- **Processed stream**: `rtsp://localhost:8554/mystream`
- **Output stream (annotated)**: `rtsp://localhost:8554/outstream`

### MQTT Topics
- **MQTT Broker**: `localhost:1883`
- **Detection results**: `yolox`
- **Pose estimation**: `rtmpose`
- **Tracking results**: `bytetrack`

## ğŸ³ Docker File Structure

```
projects/
â”œâ”€â”€ docker-compose.yml              # Main orchestration file
â”œâ”€â”€ pose_estimation_config.yaml     # Configuration file (needs link from project root)
â”œâ”€â”€ start_pose_estimation_services.sh  # Startup script
â”œâ”€â”€ prj-yolox-onnx/
â”‚   â”œâ”€â”€ Dockerfile.yaml            # YOLOX Docker file
â”‚   â”œâ”€â”€ yolox_main_yaml.py         # YOLOX main program (YAML config version)
â”‚   â””â”€â”€ yolox_worker.py            # YOLOX worker process
â”œâ”€â”€ prj-rtmpose-onnx/
â”‚   â”œâ”€â”€ Dockerfile.yaml            # RTMPose Docker file
â”‚   â”œâ”€â”€ rtmpose_main_yaml.py       # RTMPose main program (YAML config version)
â”‚   â””â”€â”€ rtmpose_worker.py          # RTMPose worker process
â”œâ”€â”€ prj-bytetrack-cpu/
â”‚   â”œâ”€â”€ Dockerfile.yaml            # ByteTrack Docker file
â”‚   â”œâ”€â”€ bytetrack_main_yaml.py     # ByteTrack main program (YAML config version)
â”‚   â””â”€â”€ bytetrack_worker.py        # ByteTrack worker process
â””â”€â”€ prj-annotation-cpu/
    â”œâ”€â”€ Dockerfile.yaml            # Annotation Docker file
    â”œâ”€â”€ annotation_main_yaml.py    # Annotation main program (YAML config version)
    â””â”€â”€ annotation_worker.py       # Annotation worker process
```

## ğŸ“Š Performance Monitoring

### View Container Status
```bash
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
```

### View Resource Usage
```bash
docker stats
```

### View GPU Usage
```bash
nvidia-smi
```

## ğŸ” Troubleshooting

### Common Issues

1. **Service startup failure**
   ```bash
   # Check logs
   docker-compose logs [service-name]
   
   # Rebuild
   docker-compose build [service-name]
   ```

2. **GPU unavailable**
   ```bash
   # Check nvidia-docker
   docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi
   ```

3. **Configuration file not found**
   ```bash
   # Ensure configuration file exists
   ls -la ../pose_estimation_config.yaml
   ```

### Debugging Steps

1. Check if base services are running properly
2. Start AI services one by one and check logs
3. Test message passing using MQTT client
4. Check if RTSP streams are accessible

## ğŸ”„ Service Dependencies

```
mqtt-broker + rtsp-server (base services)
    â†“
mp4-rtsp-source + mp4-transcode-sei (video sources)
    â†“
yolox-service (object detection)
    â†“
rtmpose-service + bytetrack-service (pose estimation + tracking)
    â†“
annotation-service (visualization)
```

## ğŸ“ Configuration Customization

### Modify Configuration Parameters

Edit the `../pose_estimation_config.yaml` file:

```yaml
# Modify device configuration
global:
  devices: "cpu"  # or "cuda"

# Modify model parameters
yolox:
  model_input_size: [640, 640]

# Modify MQTT configuration
mqtt:
  broker_host: "mqtt-broker"
  qos: 2
```

### Environment Variable Override

You can also override configuration through environment variables:

```bash
export DEVICES=cpu
export LOG_LEVEL=DEBUG
docker-compose up -d
```

