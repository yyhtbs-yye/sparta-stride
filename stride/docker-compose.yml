version: '2.4'

services:
  # MQTT message broker
  mqtt-broker:
    build: ./mqtt-broker
    container_name: mqtt-broker
    ports:
      - "1883:1883"  # MQTT port
    # volumes:
    #   - mqtt-data:/mosquitto/data
    restart: unless-stopped

  # RTSP server (MediaMTX)
  rtsp-server:
    image: bluenviron/mediamtx:latest
    cpuset: "50,51,52,53"
    container_name: rtsp-server
    ports:
      - "8554:8554"  # RTSP port
      - "1935:1935"  # RTMP port
    environment:
      - MTX_PROTOCOLS=tcp
    restart: unless-stopped

  # RTSP server (MediaMTX)
  rtsp-dashboard:
    image: bluenviron/mediamtx:latest
    cpuset: "60,61,62,63"
    container_name: rtsp-dashboard
    ports:
      - "5108:8554"  # RTSP port
      - "1937:1935"  # RTMP port
    environment:
      - MTX_PROTOCOLS=tcp
    restart: unless-stopped


  # MP4 streaming media source
  mp4-rtsp-source:
    build: ./mp4-rtsp-source-raw
    container_name: mp4_rtsp_container
    depends_on:
      - rtsp-server
    command: >
      sh -c "echo 'ðŸŽ¬ Starting video stream from $$VIDEO_FILE to $$RTSP_URL...' &&
             if [ ! -f /source-videos/media/$$VIDEO_FILE ]; then
               echo 'âŒ File not found: /source-videos/media/$$VIDEO_FILE' &&
               echo 'ðŸ“ Available files:' && ls -la /source-videos/media/ 2>/dev/null || echo 'Media directory not found' &&
               exit 1;
             fi &&
             ffmpeg -re -stream_loop -1 -i /source-videos/media/$$VIDEO_FILE
                    -c:v copy -preset veryfast -tune zerolatency
                    -c:a aac -f rtsp $$RTSP_URL"
    environment:
      - RTSP_URL=rtsp://localhost:8554/rawstream
      - VIDEO_FILE=SNMOT-153_1080p_30f.mp4
    volumes:
      - ./media:/source-videos/media:ro  # Mount local media directory
    network_mode: host
    restart: unless-stopped

  mp4-transcode-sei:
    build: ./mp4-transcoder-sei
    container_name: mp4-transcoder-sei_container
    depends_on:
      - mp4-rtsp-source
    command: 
      - sh
      - -c
      - |
        echo 'ðŸ”„ Starting transcoding from $$IN_RTSP_URL to $$OUT_RTSP_URL...'
        echo 'Testing ffmpeg availability...'
        /usr/local/bin/ffmpeg -version | head -1
        echo 'Testing x264 availability...'
        /usr/local/bin/x264 --version | head -1
        echo 'Starting transcoding pipeline...'
        sleep 2
        /usr/local/bin/ffmpeg -rtsp_transport tcp -i "$$IN_RTSP_URL" -an -f yuv4mpegpipe -pix_fmt yuv420p - | /usr/local/bin/x264 --demuxer y4m --fps 25 --preset fast --tune zerolatency --output - - | /usr/local/bin/ffmpeg -f h264 -i - -c:v copy -f rtsp -rtsp_transport tcp "$$OUT_RTSP_URL"
    environment:
      - IN_RTSP_URL=rtsp://localhost:8554/rawstream
      - OUT_RTSP_URL=rtsp://localhost:8554/mystream
    network_mode: host
    restart: unless-stopped

  # YOLOX object detection service
  yolox-service:
    build:
      context: ./prj-yolox-onnx
      dockerfile: Dockerfile
    container_name: yolox-service
    depends_on:
      - mqtt-broker
      - rtsp-server
      - mp4-transcode-sei
    command: ["bash", "-lc", "conda activate onnx && python yolox_main_yaml.py"]
    network_mode: host
    restart: unless-stopped
    runtime: nvidia  # Requires GPU support
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - PYTHONPATH=/app
      - IN_RTSP_URL=rtsp://localhost:8554,topic=mystream,client_id=yolox_in
      - OUT_MQTT_URL=mqtt://localhost:1883,topic=yolox,qos=2,queue_max_len=50,client_id=yolox_out
      - DEVICES=cuda:3
      - MODEL_INPUT_SIZE=640,640
      - MODEL_URL=https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/onnx_sdk/yolox_m_8xb8-300e_humanart-c2c7a14a.zip

  # RTMPose pose estimation service
  rtmpose-service:
    build:
      context: ./prj-rtmpose-onnx
      dockerfile: Dockerfile
    container_name: rtmpose-service
    depends_on:
      - mqtt-broker
      - yolox-service
    command: ["bash", "-lc", "conda activate onnx && python rtmpose_main_yaml.py"]
    network_mode: host
    restart: unless-stopped
    runtime: nvidia  # Requires GPU support
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - PYTHONPATH=/app
      - IN_RTSP_URL=rtsp://localhost:8554,topic=mystream
      - IN_MQTT_URL=mqtt://localhost:1883,topic=yolox,qos=2,queue_max_len=100,client_id=rtmpose_in
      - OUT_MQTT_URL=mqtt://localhost:1883,topic=rtmpose,qos=2,queue_max_len=100,client_id=rtmpose_out
      - DEVICES=cuda:1,cuda:2,cuda:3
      - MODEL_INPUT_SIZE=192,256
      - MODEL_URL=https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/onnx_sdk/rtmpose-m_simcc-body7_pt-body7_420e-256x192-e48f03d0_20230504.zip

  cmc-service:
    build:
      context: ./prj-cmc-cpu
      dockerfile: Dockerfile
    container_name: cmc-service
    depends_on:
      - mqtt-broker
      - rtsp-server
      - mp4-transcode-sei
    command: ["bash", "-lc", "conda activate cv2 && python cmc_main_yaml.py"]
    network_mode: host
    restart: unless-stopped
    environment:
      - PYTHONPATH=/app
      - IN_RTSP_URL=rtsp://localhost:8554,topic=mystream,client_id=cmc_in
      - OUT_MQTT_URL=mqtt://localhost:1883,topic=cmc,qos=2,queue_max_len=50,client_id=cmc_out

  # ByteTrack object tracking service
  bytetrack-service:
    build:
      context: ./prj-bytetrack-cpu
      dockerfile: Dockerfile
    container_name: bytetrack-service
    depends_on:
      - mqtt-broker
      - yolox-service
    command: ["bash", "-lc", "conda activate cv2 && python bytetrack_main_yaml.py"]
    network_mode: host
    restart: unless-stopped
    environment:
      - PYTHONPATH=/app
      - IN_MQTT_URL=mqtt://localhost:1883,topic=yolox,qos=2,queue_max_len=100,client_id=bytetrack_in
      - OUT_MQTT_URL=mqtt://localhost:1883,topic=bytetrack,qos=2,queue_max_len=100,client_id=bytetrack_out

  # ByteTrack object tracking service
  jerseyocr-service:
    build:
      context: ./prj-jerseyocr-gpu
      dockerfile: Dockerfile
    container_name: jerseyocr-service
    depends_on:
      - mqtt-broker
      - rtsp-server
      - mp4-transcode-sei
      - bytetrack-service
    command: ["bash", "-lc", "conda activate torch && python jerseyocr_main_yaml.py"]
    network_mode: host
    restart: unless-stopped
    runtime: nvidia  # Requires GPU support
    environment:
      - PYTHONPATH=/app
      - IN_RTSP_URL=rtsp://localhost:8554,topic=mystream
      - IN_MQTT_URL=mqtt://localhost:1883,topic=bytetrack,qos=2,queue_max_len=100,client_id=jerseyocr_in
      - OUT_MQTT_URL=mqtt://localhost:1883,topic=jerseyocr,qos=2,queue_max_len=100,client_id=jerseyocr_out
      - DEVICES=cuda:0
      - MODEL_INPUT_SIZE=256,192 # This is H,W format for Pytorch Model
      - USE_SMALL=False

  # Annotation visualization service
  annotator-service:
    build:
      context: ./prj-annotator
      dockerfile: Dockerfile
    cpuset: "90,91,92,93"
    container_name: annotator-service
    depends_on:
      - mqtt-broker
      - rtsp-server
      - bytetrack-service
      - rtmpose-service
    command: ["bash", "-lc", "conda activate cv2 && python annotator_main_yaml.py"]
    network_mode: host
    restart: unless-stopped
    environment:
      - PYTHONPATH=/app
      - IN_RTSP_URL=rtsp://localhost:8554,topic=mystream
      - IN_MQTT_URL_1=mqtt://localhost:1883,topic=bytetrack,client_id=annotator,qos=2,queue_max_len=100
      - IN_MQTT_URL_2=mqtt://localhost:1883,topic=rtmpose,client_id=annotator,qos=2,queue_max_len=100
      - IN_MQTT_URL_3=mqtt://localhost:1883,topic=cmc,client_id=annotator,qos=2,queue_max_len=100
      - IN_MQTT_URL_4=mqtt://localhost:1883,topic=jerseyocr,client_id=annotator,qos=2,queue_max_len=100
      - OUT_RTSP_URL=rtsp://0.0.0.0:5108,topic=annotated_stream,height=1080,width=1920,bitrate=7000k

volumes:
  mqtt-data:
